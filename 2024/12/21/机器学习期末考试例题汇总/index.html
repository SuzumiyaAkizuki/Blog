

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://akizukipic.oss-cn-beijing.aliyuncs.com/Cache_53fa78c0147b1e1e..jpg">
  <link rel="icon" href="https://akizukipic.oss-cn-beijing.aliyuncs.com/Cache_53fa78c0147b1e1e..jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="SuzumiyaAkizuki">
  <meta name="keywords" content="">
  
    <meta name="description" content="本文汇总了网上可以找到的北航机器学习期末考试信息，并根据所提到的题型给出一些例题。助教说本研的课程期末考试题型基本一致，因此没有进行区分。 参考文献：  北航机器学习期末考试试题2020年春 北航机器学习2020-2021秋季学期期末试题回忆 北航机器学习期末考试试题2019年秋 北航机器学习期末考试试题2021年秋 2023秋 机器学习导论 期末试题回忆版">
<meta property="og:type" content="article">
<meta property="og:title" content="北航机器学习期末考试例题汇总">
<meta property="og:url" content="https://suzumiyaakizuki.github.io/2024/12/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95%E4%BE%8B%E9%A2%98%E6%B1%87%E6%80%BB/index.html">
<meta property="og:site_name" content="凉宫秋月的文艺部">
<meta property="og:description" content="本文汇总了网上可以找到的北航机器学习期末考试信息，并根据所提到的题型给出一些例题。助教说本研的课程期末考试题型基本一致，因此没有进行区分。 参考文献：  北航机器学习期末考试试题2020年春 北航机器学习2020-2021秋季学期期末试题回忆 北航机器学习期末考试试题2019年秋 北航机器学习期末考试试题2021年秋 2023秋 机器学习导论 期末试题回忆版">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211419341.png">
<meta property="article:published_time" content="2024-12-21T02:56:50.000Z">
<meta property="article:modified_time" content="2024-12-21T10:08:54.202Z">
<meta property="article:author" content="SuzumiyaAkizuki">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211419341.png">
  
  
  
  <title>北航机器学习期末考试例题汇总 - 凉宫秋月的文艺部</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"suzumiyaakizuki.github.io","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"|","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":"#"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":3},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":false,"baidu":null,"google":"G-J01HK5TZ0Y","gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"QGqf9VPGTa96KerO0JvDW3Ld-gzGzoHsz","app_key":"RhwwUaYq4lMo1tCJwcQTWdRp","server_url":"https://qgqf9vpg.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":true}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('https://www.google-analytics.com/analytics.js', function() {
          window.ga = window.ga || function() { (ga.q = ga.q || []).push(arguments) };
          ga.l = +new Date;
          ga('create', 'G-J01HK5TZ0Y', 'auto');
          ga('send', 'pageview');
        });
      }
    </script>
  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>凉宫秋月的文艺部</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                主页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友情链接
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211419341.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="北航机器学习期末考试例题汇总"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        SuzumiyaAkizuki
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-12-21 10:56" pubdate>
          2024年12月21日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          15k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          39 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
        <div class="scroll-down-bar">
          <i class="iconfont icon-arrowdown"></i>
        </div>
      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="笔记"
        id="heading-7051dc52c184c205e39aa54b4664ae9b" role="tab" data-toggle="collapse" href="#collapse-7051dc52c184c205e39aa54b4664ae9b"
        aria-expanded="true"
      >
        笔记
        <span class="list-group-count">(28)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-7051dc52c184c205e39aa54b4664ae9b"
           role="tabpanel" aria-labelledby="heading-7051dc52c184c205e39aa54b4664ae9b">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2024/12/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95%E4%BE%8B%E9%A2%98%E6%B1%87%E6%80%BB/" title="北航机器学习期末考试例题汇总"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">北航机器学习期末考试例题汇总</span>
        </a>
      
    
      
      
        <a href="/2024/10/05/%E7%9F%A9%E9%98%B5%E7%90%86%E8%AE%BA%E7%AC%94%E8%AE%B0/" title="矩阵理论笔记"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">矩阵理论笔记</span>
        </a>
      
    
      
      
        <a href="/2024/10/03/%E6%9C%80%E4%BC%98%E5%8C%96/" title="最优化笔记"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">最优化笔记</span>
        </a>
      
    
      
      
        <a href="/2023/06/17/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86%C2%B7%E9%87%87%E6%A0%B7%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4/" title="自动控制原理·采样系统和状态空间"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">自动控制原理·采样系统和状态空间</span>
        </a>
      
    
      
      
        <a href="/2023/06/09/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86%E7%AC%94%E8%AE%B0%C2%B7%E6%95%B0%E5%AD%97%E9%80%9A%E4%BF%A1/" title="通信原理笔记·数字通信"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">通信原理笔记·数字通信</span>
        </a>
      
    
      
      
        <a href="/2023/05/26/%E4%BF%A1%E6%81%AF%E8%AE%BA%E7%AC%94%E8%AE%B0%C2%B7%E4%BF%A1%E9%81%93%E5%92%8C%E7%BC%96%E7%A0%81/" title="信息论笔记·信道和编码"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">信息论笔记·信道和编码</span>
        </a>
      
    
      
      
        <a href="/2023/05/23/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86%C2%B7%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%9F%BA%E5%B8%A6%E4%BC%A0%E8%BE%93/" title="通信原理·数字信号基带传输"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">通信原理·数字信号基带传输</span>
        </a>
      
    
      
      
        <a href="/2023/05/21/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86%EF%BC%88%E8%BD%A8%E8%BF%B9%E5%88%86%E6%9E%90%EF%BC%89/" title="自动控制原理（轨迹分析）"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">自动控制原理（轨迹分析）</span>
        </a>
      
    
      
      
        <a href="/2023/05/20/%E8%87%AA%E5%8A%A8%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86/" title="自动控制原理笔记（时域分析）"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">自动控制原理笔记（时域分析）</span>
        </a>
      
    
      
      
        <a href="/2023/05/18/%E4%BF%A1%E6%81%AF%E8%AE%BA%E7%AC%94%E8%AE%B0/" title="信息论笔记"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">信息论笔记</span>
        </a>
      
    
      
      
        <a href="/2023/05/16/%E6%A8%A1%E6%8B%9F%E8%B0%83%E5%88%B6/" title="通信原理· 调制之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">通信原理· 调制之章</span>
        </a>
      
    
      
      
        <a href="/2022/12/24/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%C2%B7%E6%BB%A4%E6%B3%A2%E5%99%A8%E4%B9%8B%E7%AB%A0/" title="数字信号处理·滤波器之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数字信号处理·滤波器之章</span>
        </a>
      
    
      
      
        <a href="/2022/12/22/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%C2%B7%E7%BB%84%E5%90%88%E4%B8%8E%E6%97%B6%E5%BA%8F%E4%B9%8B%E7%AB%A0/" title="数字电路·组合与时序之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数字电路·组合与时序之章</span>
        </a>
      
    
      
      
        <a href="/2022/12/22/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%C2%B7%E6%A8%A1%E6%8B%9F%E4%B9%8B%E7%AB%A0/" title="数字电路·模拟之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数字电路·模拟之章</span>
        </a>
      
    
      
      
        <a href="/2022/12/17/%E5%BE%AE%E6%B3%A2%C2%B7%E8%B7%AF%E4%B9%8B%E7%AB%A0/" title="微波技术·路之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">微波技术·路之章</span>
        </a>
      
    
      
      
        <a href="/2022/12/08/DSP3/" title="数字信号处理·傅里叶之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数字信号处理·傅里叶之章</span>
        </a>
      
    
      
      
        <a href="/2022/12/08/DSP2/" title="数字信号处理·系统之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数字信号处理·系统之章</span>
        </a>
      
    
      
      
        <a href="/2022/11/16/%E6%95%B0%E5%AD%97%E7%94%B5%E5%AD%90%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="数字电路·逻辑之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数字电路·逻辑之章</span>
        </a>
      
    
      
      
        <a href="/2022/11/07/%E5%BE%AE%E6%B3%A2%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/" title="微波技术·波之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">微波技术·波之章</span>
        </a>
      
    
      
      
        <a href="/2022/10/26/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%89%8D%E5%9B%9B%E7%AB%A0%E7%AC%94%E8%AE%B0/" title="数字信号处理·变换之章"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数字信号处理·变换之章</span>
        </a>
      
    
      
      
        <a href="/2022/07/03/%E5%85%B3%E4%BA%8E%E7%A6%BB%E6%95%A3%E7%B3%BB%E7%BB%9F%E5%92%8CZ%E5%8F%98%E6%8D%A2%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/" title="关于离散系统和Z变换的那些事"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">关于离散系统和Z变换的那些事</span>
        </a>
      
    
      
      
        <a href="/2022/07/01/%E5%87%89%E5%AE%AB%E7%A7%8B%E6%9C%88/" title="关于分离变量法和物质极化的那些事"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">关于分离变量法和物质极化的那些事</span>
        </a>
      
    
      
      
        <a href="/2022/06/27/%E5%85%B3%E4%BA%8E%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/" title="关于傅里叶变换的那些事"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">关于傅里叶变换的那些事</span>
        </a>
      
    
      
      
        <a href="/2022/06/21/%E5%85%B3%E4%BA%8E%E7%94%B5%E7%A3%81%E5%9C%BA%E8%BE%90%E5%B0%84%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/" title="关于电磁场辐射的那些事"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">关于电磁场辐射的那些事</span>
        </a>
      
    
      
      
        <a href="/2022/06/20/%E5%85%B3%E4%BA%8E%E7%94%B5%E7%A3%81%E5%9C%BA%E7%9A%84%E8%83%BD%E9%87%8F%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/" title="关于电磁场的能量的那些事"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">关于电磁场的能量的那些事</span>
        </a>
      
    
      
      
        <a href="/2022/06/15/%E5%85%B3%E4%BA%8E%E5%B9%B3%E9%9D%A2%E7%94%B5%E7%A3%81%E6%B3%A2%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/" title="关于平面电磁波的那些事"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">关于平面电磁波的那些事</span>
        </a>
      
    
      
      
        <a href="/2022/05/21/%E5%85%B3%E4%BA%8E%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%8F%98%E6%8D%A2%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/" title="关于拉普拉斯变换的那些事"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">关于拉普拉斯变换的那些事</span>
        </a>
      
    
      
      
        <a href="/2022/05/18/%E5%85%B3%E4%BA%8E%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E5%92%8C%E7%B3%BB%E7%BB%9F%E6%A1%86%E5%9B%BE%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/" title="关于微分方程和系统框图的那些事"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">关于微分方程和系统框图的那些事</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">北航机器学习期末考试例题汇总</h1>
            
            
              <div class="markdown-body">
                
                <p>本文汇总了网上可以找到的北航机器学习期末考试信息，并根据所提到的题型给出一些例题。助教说本研的课程期末考试题型基本一致，因此没有进行区分。</p>
<p>参考文献：</p>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43343919/article/details/112399970">北航机器学习期末考试试题2020年春</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45262065/article/details/112555104">北航机器学习2020-2021秋季学期期末试题回忆</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_38425013/article/details/103689617">北航机器学习期末考试试题2019年秋</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43787197/article/details/122240658">北航机器学习期末考试试题2021年秋</a></li>
<li><a target="_blank" rel="noopener" href="https://docsdown.oss-cn-beijing.aliyuncs.com/2023%E7%A7%8B%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA%E3%80%8B%20%E6%9C%9F%E6%9C%AB%E8%AF%95%E9%A2%98%E5%9B%9E%E5%BF%86%E7%89%88.pdf">2023秋 机器学习导论 期末试题回忆版</a></li>
</ol>
<span id="more"></span>
<p>[toc]</p>
<h2 id="贝叶斯决策">贝叶斯决策</h2>
<p>【来源】参考文献3、4</p>
<p>【例题】细胞有正常(<span class="math inline">\(w_1\)</span>)，异常(<span class="math inline">\(w_2\)</span>)两类，其先验概率为<span class="math inline">\(P(w_1)=0.9,P(w_2)=0.1\)</span>。有一个待识别的细胞，观测值为<span class="math inline">\(x\)</span>，现在已知如果细胞是正常的，出现<span class="math inline">\(x\)</span>的概率为<span class="math inline">\(0.2\)</span>；如果细胞是异常的，出现<span class="math inline">\(x\)</span>的概率是<span class="math inline">\(0.4\)</span>。决策的损失表如下：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">决策</th>
<th style="text-align: center;"><span class="math inline">\(w_1\)</span></th>
<th style="text-align: center;"><span class="math inline">\(w_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(w_1\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(w_2\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<ol type="1">
<li>基于最小错误率原则对待识别细胞进行归类</li>
<li>基于最小风险原则对待识别细胞进行归类</li>
</ol>
<p>【解答】</p>
<ol type="1">
<li><p>应用贝叶斯公式：</p>
<p>已知<span class="math inline">\(x\)</span>，细胞属于<span class="math inline">\(w_1\)</span>的概率为： <span class="math display">\[
\begin{align}
P(w_1\mid x)&amp;=\frac{P(x\mid w_1)P(w_1)}{P(x\mid w_1)P(w_1)+P(x\mid w_2)P(w_2)}\\
&amp;=\frac{0.2\times 0.9}{0.2\times 0.9+0.4\times 0.1}\\
&amp;=0.818
\end{align}
\]</span> 已知<span class="math inline">\(x\)</span>，细胞属于<span class="math inline">\(w_2\)</span>的概率为： <span class="math display">\[
\begin{align}
P(w_2\mid x)&amp;=\frac{P(x\mid w_2)P(w_2)}{P(x\mid w_1)P(w_1)+P(x\mid w_2)P(w_2)}\\
&amp;=\frac{0.4\times 0.1}{0.2\times 0.9+0.4\times 0.1}\\
&amp;=0.182
\end{align}
\]</span> 所以，应该决策为<span class="math inline">\(w_1\)</span>。</p></li>
<li><p>决策为<span class="math inline">\(w_1\)</span>的风险为： <span class="math display">\[
R(w_1)=0\times P(w_1\mid x)+6\times P(w_2\mid x)=1.092
\]</span> 决策为<span class="math inline">\(w_2\)</span>的风险为： <span class="math display">\[
R(w_2)=1\times P(w_1\mid x)+0\times P(w_2\mid x)=0.818
\]</span> 所以，应该决策为<span class="math inline">\(w_2\)</span>。</p></li>
</ol>
<h2 id="使用感知机准则求判别函数">使用感知机准则求判别函数</h2>
<p>【来源】参考文献4、5</p>
<p>【讲解】问题的格式是：现有样本集<span class="math inline">\(\{x_1,\cdots,x_n\}\)</span>属于<span class="math inline">\(w_1,w_2\)</span>两类，寻找向量<span class="math inline">\(a\)</span>，使得：<span class="math inline">\(\forall x\in w_1,a^Tx&gt;0\)</span>，且<span class="math inline">\(\forall x\in w_2,a^Tx&lt;0\)</span>。即使用一个仿射流形把样本分成两半，这时称样本是线性可分的。其具体操作步骤是：</p>
<ol type="1">
<li><p>构造规范化增广样本向量。</p>
<p>这一步的关键是增广和规范化。因为我们知道一般线性流行的表达式是<span class="math inline">\(w^Tx+b\)</span>，但是我们要把这个<span class="math inline">\(b\)</span>包含在<span class="math inline">\(w\)</span>里面，就要把样本进行增广。增广的操作步骤是给样本的坐标前面补充<span class="math inline">\(1\)</span>个<span class="math inline">\(1\)</span>。</p>
<p>规范化的意思是，如果样本是正例（属于<span class="math inline">\(w_1\)</span>），就保持不变；否则，它的每个坐标都变成相反数。</p>
<p>规范化增广样本向量记作<span class="math inline">\(\{y_1\cdots y_n\}\)</span></p></li>
<li><p>在<span class="math inline">\({y}\)</span>集合上循环迭代：对于每个<span class="math inline">\(y_i\)</span>，计算<span class="math inline">\(a_k^Ty\)</span>，如果<span class="math inline">\(a_k^Ty&lt;0\)</span>，则<span class="math inline">\(a_{k+1}=a_k+y\)</span>；否则，<span class="math inline">\(a_{k+1}=a_k\)</span>。直到对于某个<span class="math inline">\(a\)</span>，所有的<span class="math inline">\(y\)</span>都满足<span class="math inline">\(a^Ty&lt;0\)</span>，那么这就是最终结果。</p>
<p>这实际上是梯度下降法的过程，推导略。</p></li>
</ol>
<p>【例子】现有数据集：</p>
<ol type="1">
<li>类别1：<span class="math inline">\(x_1^T=(-2,2)\)</span>，<span class="math inline">\(x_2^T=(-2,-2)\)</span></li>
<li>类别2：<span class="math inline">\(x_3^T=(2,1)\)</span>，<span class="math inline">\(x_4^T=(2,-1)\)</span></li>
</ol>
<p>初始化权：<span class="math inline">\(a_0^T=(0,2,1)\)</span>，利用感知机准则求判别函数。</p>
<p>【解答】</p>
<ol type="1">
<li><p>构造规范化增广样本向量： <span class="math display">\[
y_1^T=(1,-2,2),y_2^T=(1,-2,-2)
\]</span></p>
<p><span class="math display">\[
y_3^T=(-1,-2,-1),y_4^T=(-1,-2,1)
\]</span></p></li>
<li><p>迭代</p>
<ol type="1">
<li><span class="math inline">\(a_1^Ty_1=(0,2,1)\cdot (1,-2,2)^T=-2&lt; 0\)</span>，<span class="math inline">\(a_2=a_1+y_1=(1,0,3)\)</span></li>
<li><span class="math inline">\(a_2^Ty_2=(1,0,3)\cdot (1,-2,-2)^T=-1&lt; 0\)</span>，<span class="math inline">\(a_3=a_2+y_2=(2,-2,1)\)</span></li>
<li><span class="math inline">\(a_3^Ty_3=(2,-2,1)\cdot (-1,-2,-1)^T=1&gt; 0\)</span>，<span class="math inline">\(a_4=a_3\)</span></li>
<li><span class="math inline">\(a_4^Ty_4=(2,-2,1)\cdot (-1,-2,1)^T=3&gt; 0\)</span>，<span class="math inline">\(a_5=a_4\)</span></li>
<li><span class="math inline">\(a_5^Ty_1=(2,-2,1)\cdot (1,-2,2)^T=8&gt; 0\)</span>，<span class="math inline">\(a_6=a_5\)</span></li>
<li><span class="math inline">\(a_6^Ty_2=(2,-2,1)\cdot (-1,-2,-2)^T=4&gt; 0\)</span>，<span class="math inline">\(a_6=a_5\)</span></li>
</ol>
<p>至此，对于<span class="math inline">\(a^T=(2,-2,1)\)</span>，所有的<span class="math inline">\(y\)</span>都满足<span class="math inline">\(a^Ty&lt;0\)</span>，那么这就是最终结果。</p></li>
</ol>
<h2 id="主成分分析pca数据降维方法">主成分分析（PCA）数据降维方法</h2>
<p>【来源】参考文献1、2、3、4、5</p>
<p>【讲解】PCA的考法有两种，第一种是基于最大方差准则进行推导，第二种是给你一些二维向量，让你降成一维。</p>
<p>【例题1】基于最大方差准则推导PCA的方法</p>
<p>【解答1】问题是把<span class="math inline">\(D\)</span>维数据集<span class="math inline">\(\{\boldsymbol{x}_n\}\)</span>降为<span class="math inline">\(1\)</span>维。定义投影方向为<span class="math inline">\(D\)</span>维向量<span class="math inline">\(\boldsymbol{u}\)</span>，且满足<span class="math inline">\(\boldsymbol{u}^T\boldsymbol{u}=1\)</span>。</p>
<p>则样本均值为：<span class="math inline">\(\boldsymbol{u}^T\bar {\boldsymbol{x}}\)</span>，样本方差为 <span class="math display">\[
\frac 1N \sum_{i=1}^N\boldsymbol{u}^T\boldsymbol{x}_i-\boldsymbol{u}^T\bar{\boldsymbol{x}}=\boldsymbol{u}^TS\boldsymbol{u}
\]</span> 其中<span class="math inline">\(S\)</span>是协方差矩阵。那么优化问题为： <span class="math display">\[
\begin{align}
\text{maximun} \ \ &amp;\boldsymbol{u}^TS\boldsymbol{u}\\
s.t. &amp; \boldsymbol{u}^T\boldsymbol{u}=1
\end{align}
\]</span> 利用拉格朗日乘数法，写出其拉格朗日函数： <span class="math display">\[
L(\boldsymbol{u},\lambda)=\boldsymbol{u}^TS\boldsymbol{u}+\lambda(1-\boldsymbol{u}^T\boldsymbol{u})
\]</span> 对<span class="math inline">\(\boldsymbol{u}\)</span>求导，并置零，有： <span class="math display">\[
S\boldsymbol{u}=\lambda \boldsymbol{u}
\]</span> 这意味着，<span class="math inline">\(\lambda\)</span>是<span class="math inline">\(S\)</span>的特征值，<span class="math inline">\(\boldsymbol{u}\)</span>是<span class="math inline">\(S\)</span>的特征向量。<span class="math inline">\(\boldsymbol{u}_1\)</span>是<span class="math inline">\(S\)</span>最大特征值对应的特征向量时，方差取到极大值，称<span class="math inline">\(\boldsymbol{u}_1\)</span>为第一主成分。于是，我们得到利用PCA降维的操作步骤：</p>
<ol type="1">
<li><p>计算所有样本点的均值<span class="math inline">\(\boldsymbol{\bar x}\)</span></p></li>
<li><p>对所有样本点进行零均值化：<span class="math inline">\(\boldsymbol{x_i}=\boldsymbol{x_i-\bar x}\)</span></p></li>
<li><p>计算协方差阵： <span class="math display">\[
S=\frac 1N\sum_{i=1}^N \boldsymbol{x}_i\boldsymbol{x}_i^T
\]</span></p></li>
<li><p>计算协方差阵的最大的特征值和与其对应的特征向量<span class="math inline">\(\boldsymbol{u}\)</span></p></li>
<li><p>进行投影：<span class="math inline">\(y=\boldsymbol{u}^T\boldsymbol{x}\)</span></p></li>
</ol>
<p>【例题2】对以下五个二维向量，利用PCA降为一维 <span class="math display">\[
x_{(1)} = \begin{bmatrix} 2 \\ 5 \end{bmatrix}, \quad
x_{(2)} = \begin{bmatrix} 3 \\ 3 \end{bmatrix}, \quad
x_{(3)} = \begin{bmatrix} 5 \\ 4 \end{bmatrix}, \quad
x_{(4)} = \begin{bmatrix} 4 \\ 6 \end{bmatrix}, \quad
x_{(5)} = \begin{bmatrix} 6 \\ 2 \end{bmatrix}
\]</span> 【解答2】</p>
<ol type="1">
<li><p>计算样本均值： <span class="math display">\[
\bar {\boldsymbol{x}}=\begin{bmatrix} 4 \\ 4 \end{bmatrix}
\]</span></p></li>
<li><p>零均值化： <span class="math display">\[
x_{(1)} = \begin{bmatrix} -2 \\ 1 \end{bmatrix}, \quad
x_{(2)} = \begin{bmatrix} -1 \\ -1 \end{bmatrix}, \quad
x_{(3)} = \begin{bmatrix} 1 \\ 0 \end{bmatrix}, \quad
x_{(4)} = \begin{bmatrix} 0 \\ 2 \end{bmatrix}, \quad
x_{(5)} = \begin{bmatrix} 2 \\ -2 \end{bmatrix}
\]</span></p></li>
<li><p>计算协方差矩阵： <span class="math display">\[
S=\begin{bmatrix}
     2  &amp;  -1\\
    -1   &amp; 2\\
\end{bmatrix}
\]</span></p></li>
<li><p>计算特征值和特征向量：</p>
<p>最大的特征值为<span class="math inline">\(\lambda=3\)</span>，对应的特征向量为： <span class="math display">\[
\boldsymbol{u}=\begin{bmatrix} -\dfrac{1}{\sqrt{2}} \\ \dfrac{1}{\sqrt{2}} \end{bmatrix}
\]</span></p></li>
<li><p>进行投影：</p>
<p><span class="math inline">\(y=\boldsymbol{u}^T\boldsymbol{x}\)</span></p></li>
</ol>
<p>【例题3】简述PCA和Fisher准则的区别</p>
<p>【解答3】（以下文字是AI生成的）</p>
<p>PCA（主成分分析）和Fisher准则（Fisher线性判别分析）都是降维技术，但它们的目标和方法有所不同：</p>
<ol type="1">
<li><strong>目标不同</strong>：
<ul>
<li><strong>PCA</strong>：主要目的是数据压缩和特征提取，通过正交变换将数据转换到新的坐标系，使得数据的任何投影的第一大方差在第一个坐标（称为第一主成分）上，第二大方差在第二个坐标上，依此类推。PCA不涉及监督学习，即不考虑数据的标签信息。</li>
<li><strong>Fisher准则</strong>：是一种监督学习的降维技术，目的是寻找最佳的投影方向，使得不同类别的数据在该方向上的距离尽可能远，而同类数据尽可能近。它利用了数据的类别标签信息。</li>
</ul></li>
<li><strong>方法不同</strong>：
<ul>
<li><strong>PCA</strong>：通过协方差矩阵的特征值和特征向量来确定主成分，选择的是数据方差最大的方向。</li>
<li><strong>Fisher准则</strong>：通过最大化类间散度与类内散度的比值来确定最佳投影方向，选择的是区分不同类别最有效的方向。</li>
</ul></li>
<li><strong>应用场景不同</strong>：
<ul>
<li><strong>PCA</strong>：适用于无监督学习场景，比如数据压缩、去噪等。</li>
<li><strong>Fisher准则</strong>：适用于监督学习场景，尤其是分类问题中的特征提取和降维。</li>
</ul></li>
<li><strong>对数据的要求不同</strong>：
<ul>
<li><strong>PCA</strong>：对数据的分布没有特别的要求，可以处理各种类型的数据。</li>
<li><strong>Fisher准则</strong>：要求数据是分类的，需要知道每个数据点的类别标签。</li>
</ul></li>
</ol>
<p>总结来说，PCA是一种无监督的降维方法，关注于数据的方差；而Fisher准则是一种监督的降维方法，关注于类别的区分度。</p>
<h2 id="支持向量机">支持向量机</h2>
<p>【来源】参考文献1、2、3、4、5</p>
<p>【讲解】支持向量机的考法一般是让你简述一下原理，然后问一下软间隔和核函数。</p>
<p>【例题】svm的基本思想，模型表达式，软间隔和硬间隔的物理含义，如何用来解决非线性问题</p>
<p>【解答】对于分类问题：在空间中找一个超平面，最大化地分开不同数据点。对于样本<span class="math inline">\(\{\boldsymbol{x}_i,t_i\}\)</span>，其中<span class="math inline">\(\boldsymbol{x}_i\)</span>是空间中的点，<span class="math inline">\(t_i\in \{-1,1\}\)</span>是标签。找一个分类器<span class="math inline">\(y=\boldsymbol{w^Tx+b}\)</span>，使得：</p>
<p><span class="math display">\[
t_i=\begin{cases}
1,&amp;y(\boldsymbol{x}_i)&gt;0\\
-1&amp;y(\boldsymbol{x}_i)&lt;0
\end{cases}
\]</span></p>
<p>SVM的思想是，寻找一个超平面，使其两端的空白区最大，即：</p>
<p>$$ <span class="math display">\[\begin{align}
\text{maximun}_{w,b}\ \ &amp;\frac{1}{\|w\|}|\boldsymbol{w^Tx_i+b_i}|\\
s.t.\ \ &amp; t_i(\boldsymbol{w_i^Tx_i+b_i})\geq 1

\end{align}\]</span> $$</p>
<p>问题等价为：</p>
<p><span class="math display">\[
\begin{align}
\text{minimun}_{w,b}\ \ &amp; \frac {1}{2} \boldsymbol{w^Tw}\\
s.t.\ \ &amp; t_i(\boldsymbol{w_i^Tx_i+b_i})\geq 1
\end{align}
\]</span></p>
<p>这就是SVM的基本型。利用拉格朗日乘数法的对偶问题，可以写出其对偶型</p>
<p><span class="math display">\[
\begin{align}
\text{minimum}_\alpha\ \ &amp;\sum_{i=1}^N \sum_{j=1}^N \alpha_i
\alpha_j t_i t_j \boldsymbol{x_i^Tx_j}-\sum_{i=1}^N \alpha_i\\
s.t. \ \ &amp;\alpha&gt;0\\
&amp; \sum_{i=1}^N \alpha_i t_i=0
\end{align}
\]</span></p>
<p>核技巧是应对非线性可分问题的一种方法。在<span class="math inline">\(\mathbb R^d\)</span>中，如果<span class="math inline">\(\{\boldsymbol{x}_i,t_i\}\)</span>不是线性可分的，则必定存在一个映射<span class="math inline">\(\phi : \mathbb R^d\to \mathbb R^{d&#39;}\)</span>，使得<span class="math inline">\(\{\phi(\boldsymbol{x}_i),t_i\}\)</span>在<span class="math inline">\(\mathbb R^{d&#39;}\)</span>中是线性可分的，其中一般有<span class="math inline">\(d&#39;\geq d\)</span>。此时，SVM的对偶问题变为：</p>
<p><span class="math display">\[
\begin{align}
\text{minimum}_\alpha\ \ &amp;\sum_{i=1}^N \sum_{j=1}^N \alpha_i
\alpha_j t_i t_j \phi^T(\boldsymbol{x_i})\phi(\boldsymbol{x_j})-\sum_{i=1}^N \alpha_i\\
s.t. \ \ &amp;\alpha&gt;0\\
&amp; \sum_{i=1}^N \alpha_i t_i=0
\end{align}
\]</span></p>
<p>所谓的核技巧，就是寻找一个函数<span class="math inline">\(k(\boldsymbol{x_i,x_j})\)</span>，使得</p>
<p><span class="math display">\[
k(\boldsymbol{x_i,x_j})=\phi^T(\boldsymbol{x_i})\phi(\boldsymbol{x_j})
\]</span></p>
<p>且计算<span class="math inline">\(k\)</span>的复杂度是<span class="math inline">\(d\)</span>，这样就能够加速计算。常用的核有：</p>
<ol type="1">
<li>线性核：<span class="math inline">\(k=x_i^Tx_j\)</span>，<span class="math inline">\(d\to d\)</span></li>
<li>多项式核：<span class="math inline">\(k=(\gamma x_i^Tx_j+c)^k\)</span>，<span class="math inline">\(d\to C_{k}^{d+k}\)</span></li>
<li>高斯核：<span class="math inline">\(k=\exp(-\gamma \|x_i-x_j\|^2)\)</span>，<span class="math inline">\(d\to \infty\)</span></li>
</ol>
<p>还有一种线性不可分是数据噪声造成的，这时可以用软间隔法。对于每一个样本引入一个松弛变量<span class="math inline">\(\epsilon\)</span>，原始问题变成：</p>
<p><span class="math display">\[
\begin{align}
\text{minimun}_{w,b}\ \ &amp; \frac {1}{2} \boldsymbol{w^Tw}\\
s.t.\ \ &amp; t_i(\boldsymbol{w_i^Tx_i+b_i})\geq 1-\epsilon_i
\end{align}
\]</span></p>
<p>对偶问题变成：</p>
<p><span class="math display">\[
\begin{align}
\text{minimum}_\alpha\ \ &amp;\sum_{i=1}^N \sum_{j=1}^N \alpha_i
\alpha_j t_i t_j \phi^T(\boldsymbol{x_i})\phi(\boldsymbol{x_j})-\sum_{i=1}^N \alpha_i\\
s.t. \ \ &amp;\alpha\in (0,C)\\
&amp; \sum_{i=1}^N \alpha_i t_i=0
\end{align}
\]</span></p>
<h2 id="k-means算法em算法">K-Means算法、EM算法</h2>
<p>【来源】参考文献1、2、3、4、5</p>
<p>【讲解】一般都是考概念题，问你K均值算法、高斯混合模型、EM算法分别是什么，有什么改进空间等。</p>
<h3 id="k均值算法">K均值算法</h3>
<p>定义：给定 D 维空间上的数据集 <span class="math inline">\(X=\left\{\mathbf{x}_1, \ldots, \mathbf{x}_N\right\}\)</span>, 这些数据对应类别未知。K均值算法将数据集划分成 <span class="math inline">\(K\)</span> 类, 各类的聚类中心记为 <span class="math inline">\(\mu_1, \ldots, \mu_k\)</span>, 并将每一个样本 <span class="math inline">\(\mathrm{x}_n\)</span> 划归到离该样本最近的聚类中心。</p>
<p>K均值算法的一般流程</p>
<ol type="1">
<li><p>初始化选择K个初始聚类中心</p></li>
<li><p>将每个数据点划分给最近的聚类中心 <span class="math inline">\(\mu_k\)</span>, 得到聚类标注 <span class="math inline">\(r_n\)</span></p></li>
<li><p>最小化准则函数, 重新计算聚类中心 <span class="math inline">\(\mu_k\)</span>。求解方法：对<span class="math inline">\(\mu_k\)</span>求导并置零。 <span class="math display">\[
J=\sum_{n=1}^N \sum_{k=1}^K r_{n k}\left\|\boldsymbol{x}_n-\mu_k\right\|^2
\]</span> 求导： <span class="math display">\[
2 \sum_{n=1}^N r_{n k}\left(\boldsymbol{x}_n-\mu_k\right)=0
\]</span> 求解： <span class="math display">\[
\mu_k=\frac{\sum_n r_{n k} \boldsymbol{x}_n}{\sum_n r_{n k}}
\]</span></p></li>
<li><p>迭代步骤2和3, 直到满足终止条件：聚类中心不再发生显著变化或达到最大迭代次数</p></li>
</ol>
<h3 id="高斯混合模型">高斯混合模型</h3>
<p>是一种统计模型, 用于表示一组数据是由多个高斯分布混合而成的。具体地，高斯混合模型是多个高斯分布的线性组合，每个高斯分布称为一个混合成分, 每个混合成分都有一个对应的混合系数, 所有混合系数的和为 1</p>
<p><span class="math display">\[
\begin{aligned}
&amp; p(x)=\sum_i \alpha_i \mathcal{N}\left(x \mid \mu_i, \Sigma_i\right), \sum_i \alpha_i=1 \\
\end{aligned}
\]</span></p>
<p>GMM能够捕捉数据的多峰特性, 即数据集中可能存在多个簇, 每个簇的分布可以用一个高斯分布来描述。GMM广泛应用于聚类分析、图像分割、语音识别、数据降维等领域。</p>
<h3 id="em算法">EM算法</h3>
<p>EM算法是一种分步迭代优化算法, 适用于包含隐变量的极大似然估计问题。在高斯混合问题中, EM算法通过迭代更新隐变量 <span class="math inline">\(z_n\)</span> 的估计值和GMM的模型参数，使得对数似然函数逐步逼近最大值。通过计算 <span class="math inline">\(z_n\)</span> 的估计值, 可以消除隐变量的影响, 去掉 <span class="math inline">\(\ln\)</span> 函数中的求和项 具体地，EM算法包含两个步骤。E-step：固定GMM的模型参数, 计算隐变量 <span class="math inline">\(z_n\)</span> 的估计值, 即样本属于每个高斯分布的后验概率；M-step：已知隐变量 <span class="math inline">\(z_n\)</span> 的估计值，通过极大似然估计更新GMM的模型参数</p>
<h2 id="集成学习">集成学习</h2>
<p>【来源】参考文献1、2、5</p>
<p>【讲解】只考过一种题。</p>
<p>【例题】简述集成学习的基本思想，简述Boosting和Bagging的原理和区别</p>
<p>【解答】集成学习的基本思想是通过多个学习器进行集成，可以获得比单一学习器更优的泛化性能。其关键是如何产生「好而不同」的个体学习器。</p>
<p>Boosting是串行方法，即先训练一个学习器，然后对训练集的样本分布进行调整，使得先前错分的样本的权重增加，然后以新的训练集训练新的学习器。如此重复，直到获得够多的学习器，然后进行加权组合。其特点有：</p>
<ol type="1">
<li>弱模型、偏差高、方差低</li>
<li>个体学习器之间有强依赖，串行生成</li>
<li>不能显著降低方差。</li>
</ol>
<p>Bagging是并行方法，基于自主采样法，构造<span class="math inline">\(T\)</span>个含<span class="math inline">\(m\)</span>个样本的采样集，基于每个采样集训练一个学习器。其特点有：方差低、易于并行、无法降低偏差。</p>
<h2 id="决策树">决策树</h2>
<p>【来源】参考文献1、2、3、4、5</p>
<p>【讲解】考法是使用ID3构造决策树，然后简述预剪枝和后剪枝法。</p>
<p>【例题】用ID3算法对下面的数据集进行分类，根据星球的大小和轨道判断其是否宜居：</p>
<table>
<thead>
<tr class="header">
<th>数量</th>
<th>大小</th>
<th>轨道</th>
<th>是否宜居</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>30</td>
<td>大</td>
<td>远</td>
<td>是</td>
</tr>
<tr class="even">
<td>130</td>
<td>大</td>
<td>近</td>
<td>是</td>
</tr>
<tr class="odd">
<td>48</td>
<td>小</td>
<td>远</td>
<td>是</td>
</tr>
<tr class="even">
<td>161</td>
<td>小</td>
<td>近</td>
<td>是</td>
</tr>
<tr class="odd">
<td>20</td>
<td>大</td>
<td>远</td>
<td>否</td>
</tr>
<tr class="even">
<td>170</td>
<td>大</td>
<td>近</td>
<td>否</td>
</tr>
<tr class="odd">
<td>11</td>
<td>小</td>
<td>远</td>
<td>否</td>
</tr>
<tr class="even">
<td>230</td>
<td>小</td>
<td>近</td>
<td>否</td>
</tr>
</tbody>
</table>
<ol type="1">
<li><p>以分类目标为样本，计算总体信息熵： <span class="math display">\[
P(宜居)=\frac{369}{800},P(不宜居)=\frac{431}{800}
\]</span> 熵： <span class="math display">\[
H_{总体}=-(P(宜居)\log_2(P(宜居))+P(不宜居)\log_2(P(不宜居)))=0.9957
\]</span></p></li>
<li><p>计算属性：大小的信息增益：</p>
<ol type="1">
<li><p>大小-大： <span class="math display">\[
P(宜居|大)=\frac{160}{350},P(不宜居|大)=\frac{190}{350}
\]</span></p>
<p><span class="math display">\[
H_{大}=0.9947
\]</span></p></li>
<li><p>大小-小： <span class="math display">\[
P(宜居|小)=\frac{209}{450},P(不宜居|小)=\frac{241}{450}
\]</span></p>
<p><span class="math display">\[
H_{小}=0.9963
\]</span></p></li>
</ol>
<p>期望信息熵为： <span class="math display">\[
H_{大小}=P(大)H_{大}+P(小)H_{小}=0.9956
\]</span> 信息增益 <span class="math display">\[
G_{大小}=H_{总}-H_{大小}=0.001
\]</span></p></li>
<li><p>计算属性：轨道的信息增益</p>
<ol type="1">
<li><p>轨道-近： <span class="math display">\[
P(宜居|近)=\frac{291}{691},P(不宜居|近)=\frac{400}{691}
\]</span></p>
<p><span class="math display">\[
H_{近}=0.9820
\]</span></p></li>
<li><p>轨道-远： <span class="math display">\[
P(宜居|远)=\frac{78}{109},P(不宜居|远)=\frac{31}{109}
\]</span></p>
<p><span class="math display">\[
H_{远}=0.8614
\]</span></p></li>
</ol>
<p>期望信息熵为： <span class="math display">\[
H_{轨道}=P(近)H_{近}+P(远)H_{小=远}=0.9656
\]</span> 信息增益 <span class="math display">\[
G_{轨道}=0.0301
\]</span></p></li>
<li><p>所以，第一个结点为「轨道」：</p>
<figure>
<img src="https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211550252.png" srcset="/img/loading.gif" lazyload alt="image-20241221155055706" /><figcaption aria-hidden="true">image-20241221155055706</figcaption>
</figure></li>
<li><p>计算子树T1</p>
<p>因为 <span class="math display">\[
P(宜居|大,近)&lt;P(不宜居|大,近)
\]</span></p>
<p><span class="math display">\[
P(宜居|小,近)&lt;P(不宜居|小,近)
\]</span></p>
<p>所以<span class="math inline">\(T_1\)</span>为叶结点，置为「不宜居」</p></li>
<li><p>计算子树<span class="math inline">\(T_2\)</span> <span class="math display">\[
P(宜居|大,远)&gt;P(不宜居|大,远)
\]</span></p>
<p><span class="math display">\[
P(宜居|小,远)&gt;P(不宜居|小,远)
\]</span></p>
<p>所以<span class="math inline">\(T_2\)</span>为叶结点，置为「宜居」</p>
<figure>
<img src="https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211558936.png" srcset="/img/loading.gif" lazyload alt="image-20241221155847215" /><figcaption aria-hidden="true">image-20241221155847215</figcaption>
</figure></li>
</ol>
<p>【例题2】描述预剪枝法和后剪枝法的方法和优缺点</p>
<p>【解答】（以下内容由AI生成）</p>
<p>预剪枝法（Pre-pruning）</p>
<p><strong>具体方法</strong>： 预剪枝是在决策树生成的过程中，对每个节点在划分前先进行估计，如果当前节点的划分不能带来决策树泛化性能提升，则停止划分，并将当前节点标记为叶子节点。常见的预剪枝策略包括限制树的最大深度、限制叶节点的最小样本数量、限制节点划分所需的最小信息增益等。</p>
<p><strong>优点</strong>： 1. <strong>降低过拟合风险</strong>：通过限制树的生长，减少过拟合的可能性。 2. <strong>减少训练和测试时间</strong>：由于树的生长被提前终止，可以减少模型的训练和预测时间。</p>
<p><strong>缺点</strong>： 1. <strong>欠拟合风险</strong>：由于提前停止树的生长，可能会错过一些对模型性能有益的分支，导致模型欠拟合。 2. <strong>视野效应问题</strong>：可能在当前划分看似不能提升性能的情况下，进一步的扩展能够显著提高性能，预剪枝会导致算法过早停止。</p>
<p>后剪枝法（Post-pruning）</p>
<p><strong>具体方法</strong>： 后剪枝是在决策树完全生长之后进行的剪枝，它首先生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。常见的后剪枝方法包括错误率降低剪枝（REP）、悲观错误剪枝（PEP）、代价复杂度剪枝（CCP）等。</p>
<p><strong>优点</strong>： 1. <strong>泛化性能通常优于预剪枝</strong>：后剪枝保留了更多的分支，使得模型有更大的空间去学习和适应数据的复杂模式。 2. <strong>减少欠拟合风险</strong>：相较于预剪枝，后剪枝的欠拟合风险更小。</p>
<p><strong>缺点</strong>： 1. <strong>训练时间开销大</strong>：后剪枝需要在生成完全决策树之后进行剪枝，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。 2. <strong>计算资源需求高</strong>：由于需要在完整的决策树上进行剪枝操作，后剪枝需要更多的计算资源。</p>
<p>总结来说，预剪枝和后剪枝都是为了解决决策树的过拟合问题，提高模型的泛化能力。预剪枝通过提前停止树的生长来减少过拟合风险，但可能会增加欠拟合风险；而后剪枝通过在完全生成树之后进行剪枝，通常能获得更好的泛化性能，但需要更多的计算资源和时间。在实际应用中，需要根据具体的问题和数据集选择合适的剪枝策略。</p>
<h2 id="概率图模型">概率图模型</h2>
<p>【来源】参考文献1、2、3</p>
<p>【讲解】这部分的考法就是考贝叶斯网络或者马尔可夫场。先问你马尔可夫概率图的最大团，然后再让你写出两个概率图的联合分布。</p>
<p>其中贝叶斯网络是一个DAG（有向无环图）</p>
<figure>
<img src="https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211606705.png" srcset="/img/loading.gif" lazyload alt="贝叶斯概率图" /><figcaption aria-hidden="true">贝叶斯概率图</figcaption>
</figure>
<p>它的联合分布就从底向上一层层写即可，如下： <span class="math display">\[
P(x_1)P(x_2)P(x_3)P(x_4|x_1,x_2,x_3)P(x_5|x_1,x_3)P(x_6|x_4)P(x_7|x_4,x_5)
\]</span> 马尔可夫场是一个无向图，如下：</p>
<figure>
<img src="https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211612602.png" srcset="/img/loading.gif" lazyload alt="image-20241221161219707" /><figcaption aria-hidden="true">image-20241221161219707</figcaption>
</figure>
<p>所谓的「团」指的是任意两点之间都有边的子集。最大团指的是不能被其它团包含的团。图中的蓝色框线就是两个最大团。</p>
<p>马尔可夫场的联合概率分布基于最大团分解为多个因子的乘积，设所有最大团构成的集合为<span class="math inline">\(C\)</span>，则联合概率分布为</p>
<p><span class="math display">\[
P(X)=\frac{1}{Z} \prod_{Q \in C} \psi_Q\left(X_Q\right)
\]</span> 上图的概率分布为： <span class="math display">\[
P\left(x_1, x_2, x_3, x_4\right)=\frac{1}{Z} \psi_{123}\left(x_1, x_2, x_3\right) \psi_{34}\left(x_3, x_4\right)
\]</span></p>
<h2 id="bp反向传播算法">BP反向传播算法</h2>
<p>【来源】参考文献1、2、3、4、5</p>
<p>【讲解】</p>
<p>首先记住这个神经元的基本结构，尤其记住各个符号的含义：</p>
<figure>
<img src="https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211700434.png" srcset="/img/loading.gif" lazyload alt="神经元的基本结构" /><figcaption aria-hidden="true">神经元的基本结构</figcaption>
</figure>
<ol type="1">
<li><p><span class="math inline">\(x_1\cdots x_N\)</span>：前一层的输入</p></li>
<li><p><span class="math inline">\(w_1\cdots w_N\)</span>：权值，也是神经网络训练的目标</p></li>
<li><p><span class="math inline">\(\Sigma\)</span>：求和器</p></li>
<li><p><span class="math inline">\(\theta\)</span>：求和器阈值，可有可无</p></li>
<li><p><span class="math inline">\(a\)</span>： <span class="math display">\[
a=\sum_{i=1}^Nx_iw_i-\theta
\]</span></p></li>
<li><p><span class="math inline">\(f\)</span>：激活函数，就是ReLU啊、Sigmoid啊之类的</p></li>
<li><p><span class="math inline">\(y\)</span>：神经元输出 <span class="math display">\[
y=f(a)
\]</span></p></li>
</ol>
<p>之后的神经网络图中，每一个「圆点」，其实都暗含了这些东西。</p>
<p>所谓的反向传播算法，就是定义一个损失函数： <span class="math display">\[
E(w)=\frac 12 \sum_{i=1}^N (y(x_i,w)-t_i)^2
\]</span> 计算它的梯度<span class="math inline">\(\nabla E(w)\)</span>，然后用梯度下降法更新<span class="math inline">\(w\)</span>。</p>
<p>算法可以分为两个阶段：</p>
<ol type="1">
<li>前馈(正向过程)：从输入层经隐层逐层正向计算各单元的输出；</li>
<li>学习(反向过程)：由输出误差逐层反向计算隐层各单元的误差，并用此误差修正前层的权值</li>
</ol>
<figure>
<img src="https://akizukipic.oss-cn-beijing.aliyuncs.com/img/202412211720451.png" srcset="/img/loading.gif" lazyload alt="image-20241221172009190" /><figcaption aria-hidden="true">image-20241221172009190</figcaption>
</figure>
<p>现在，我们要计算<span class="math inline">\(E\)</span>对<span class="math inline">\(w\)</span>的导数，记激活函数为<span class="math inline">\(h\)</span>。我们知道<span class="math inline">\(E\)</span>是<span class="math inline">\(y\)</span>的函数，<span class="math inline">\(y\)</span>是<span class="math inline">\(a\)</span>的函数，<span class="math inline">\(a\)</span>是<span class="math inline">\(w,x\)</span>的函数，故： <span class="math display">\[
\begin{aligned}
\frac{\partial E_n}{\partial w_{k j}} &amp; =\frac{\partial E_n}{\partial y_k} \frac{\partial y_k}{\partial a_k} \frac{\partial a_k}{\partial w_{k j}} \\
&amp; =\left(y_k-t_k\right) \frac{\partial y_k}{\partial a_k} \frac{\partial a_k}{\partial w_{k j}} \\
&amp; =\left(y_k-t_k\right) h^{\prime}\left(a_k\right) \frac{\partial a_k}{\partial w_{k j}} \\
&amp; =\left(y_k-t_k\right) h^{\prime}\left(a_k\right) x_j
\end{aligned}
\]</span> 现在，如果要计算<span class="math inline">\(j\)</span>层的梯度，即： <span class="math display">\[
\frac{\partial E_n}{\partial w_{j i}}=\frac{\partial E_n}{\partial a_j} \frac{\partial a_j}{\partial w_{j i}}
\]</span></p>
<p>接下来使用两个记号： <span class="math display">\[
\delta_j=\frac{\partial E_n}{\partial y_j} \frac{\partial y_j}{\partial a_j}=\frac{\partial E_n}{\partial a_j}
\]</span> 和 <span class="math display">\[
z_i=\frac{\partial a_k}{\partial w_{k i}}
\]</span> 则有 <span class="math display">\[
\frac{\partial E_n}{\partial w_{j i}}=\delta_j z_i
\]</span> 因为上面已经求出了输出层的误差，根据误差反向传播的原理，当前层的误差可理解为上一层所有神经元误差的复合函数，即使用上一层的误差来表示当前层误差，并依次递推。有： <span class="math display">\[
\delta_j=\frac{\partial E_n}{\partial a_{j}}=\frac{\partial E_n}{\partial a_{k}}\frac{\partial a_{k}}{\partial a_j}
\]</span> 其中 <span class="math display">\[
a_{k}=\sum_{k}w_{kj}h(a_{j})
\]</span> 故： <span class="math display">\[
\delta_j=h^{\prime}\left(a_j\right) \sum_k w_{k j} \delta_k
\]</span> 这样，我们就推导出了反向传播的递推式。</p>
<p>整体算法流程</p>
<ol type="1">
<li><p>初始化权重 <span class="math inline">\(w_{i j}\)</span></p></li>
<li><p>对于输入的训练样本, 求取每个节点输出和最终输出层的输出值</p></li>
<li><p>对于输出层求 <span class="math display">\[
\delta_k=y_k-t_k
\]</span></p></li>
<li><p>对于隐藏层求 <span class="math display">\[
\quad \delta_j=h^{\prime}\left(a_j\right) \sum_k w_{k j} \delta_k
\]</span></p></li>
<li><p>求输出误差对于每个权重的梯度 <span class="math display">\[
\frac{\partial E_n}{\partial w_{j i}}=\delta_j x_i
\]</span></p></li>
<li><p>更新权重 <span class="math display">\[
\quad \mathbf{w}^{(\tau+1)}=\mathbf{w}^{(\tau)}-\eta \nabla E\left(\mathbf{w}^{(\tau)}\right)
\]</span></p></li>
</ol>
<p>此外，还要记住一个结论： <span class="math display">\[
\sigma&#39;(x)=\sigma(x)(1-\sigma(x))
\]</span> 其中<span class="math inline">\(\sigma\)</span>是Sigmoid函数，即 <span class="math display">\[
\sigma(x)=\frac 1{1+e^{-x}}
\]</span></p>
<h2 id="开放性试题">开放性试题</h2>
<p>【来源】参考文献1、2、3、4、5</p>
<p>【讲解】每张卷子的最后一题是开放性试题。</p>
<p>【例题1】谈谈你对深度学习的理解，深度学习模型存在什么问题，你觉得深度学习未来会往什么方向发展。</p>
<p>【解答1】（以下解答由AI生成）</p>
<p><strong>我对深度学习的理解</strong></p>
<p>深度学习是机器学习的一个子领域，它基于人工神经网络的学习算法，特别是那些具有多个非线性变换的层（即深度）。这些层可以学习数据的复杂模式和表示。深度学习模型能够自动从原始数据中提取特征，而不需要人为设计特征提取算法。这种能力使得深度学习在图像识别、语音识别、自然语言处理等领域取得了革命性的进展。</p>
<p><strong>深度学习模型存在的问题</strong></p>
<ol type="1">
<li><strong>数据需求</strong>：深度学习模型通常需要大量的标注数据来训练，这在某些领域（如医疗图像分析）可能是不切实际的。</li>
<li><strong>可解释性</strong>：深度学习模型通常被认为是“黑箱”，因为它们的决策过程缺乏透明度，难以解释。</li>
<li><strong>计算资源</strong>：训练深度学习模型需要大量的计算资源，这可能导致成本高昂和能源消耗问题。</li>
<li><strong>过拟合</strong>：在有限的数据集上训练时，深度学习模型可能会过拟合，即在训练数据上表现很好，但在未见过的数据上表现差。</li>
<li><strong>对抗性脆弱性</strong>：深度学习模型可能对精心设计的输入（对抗性样本）非常敏感，这些输入可以导致模型做出错误的预测。</li>
<li><strong>泛化能力</strong>：在某些情况下，深度学习模型可能难以泛化到新的、未见过的数据或任务上。</li>
</ol>
<p><strong>深度学习未来的发展方向</strong></p>
<ol type="1">
<li><strong>更少的数据需求</strong>：研究者正在探索如何使用更少的数据来训练有效的深度学习模型，例如通过迁移学习、元学习和数据增强技术。</li>
<li><strong>提高可解释性</strong>：深度学习模型的可解释性是一个活跃的研究领域，目标是使模型的决策过程更加透明和可理解。</li>
<li><strong>节能和效率</strong>：随着对环境影响的关注增加，研究者正在寻找更节能的算法和硬件来训练和部署深度学习模型。</li>
<li><strong>对抗性鲁棒性</strong>：提高模型对对抗性攻击的鲁棒性是一个重要的研究方向，以确保模型在现实世界中的可靠性。</li>
<li><strong>泛化能力</strong>：研究者正在探索如何提高深度学习模型的泛化能力，使其能够更好地适应新环境和任务。</li>
<li><strong>跨领域应用</strong>：深度学习可能会扩展到新的领域，如生物信息学、材料科学和量子计算。</li>
<li><strong>集成学习</strong>：结合不同的模型和算法来提高性能和鲁棒性，例如集成学习。</li>
<li><strong>伦理和公平性</strong>：随着深度学习在社会中应用的增加，确保模型的公平性和避免偏见成为一个重要议题。</li>
<li><strong>自动机器学习（AutoML）</strong>：自动化深度学习模型的设计和训练过程，使非专家也能轻松使用深度学习技术。</li>
</ol>
<p>深度学习是一个快速发展的领域，随着技术的进步和新挑战的出现，未来的发展方向可能会不断变化。</p>
<p>【例题2】给出机器学习和深度学习的联系，各有什么优缺点</p>
<p>【解答2】（以下解答由AI生成）</p>
<p>机器学习和深度学习是人工智能领域中密切相关的两个概念，它们之间存在一些联系和区别。</p>
<p><strong>联系</strong></p>
<ol type="1">
<li><strong>基础理论</strong>：深度学习是机器学习的一个子集，它基于机器学习的一些核心概念，如模式识别和学习算法。</li>
<li><strong>目标</strong>：两者都旨在从数据中学习，并做出预测或决策。</li>
<li><strong>数据驱动</strong>：机器学习和深度学习都依赖于数据来训练模型，并通过数据改进模型的性能。</li>
<li><strong>特征学习</strong>：深度学习是机器学习中特征学习的一个特例，它能够自动从原始数据中提取复杂的特征。</li>
</ol>
<p><strong>机器学习的优点</strong></p>
<ol type="1">
<li><strong>灵活性</strong>：机器学习算法（如支持向量机、决策树、随机森林等）适用于各种不同的数据类型和问题。</li>
<li><strong>可解释性</strong>：某些机器学习模型（如决策树）相对容易解释，有助于理解模型的决策过程。</li>
<li><strong>数据效率</strong>：一些机器学习算法可以在较小的数据集上训练，不需要像深度学习那样大量的数据。</li>
<li><strong>适应性</strong>：机器学习模型可以更容易地适应新的数据分布，尤其是在数据分布发生变化时。</li>
</ol>
<p><strong>机器学习的缺点</strong></p>
<ol type="1">
<li><strong>特征工程</strong>：在传统的机器学习中，特征工程是一个耗时且需要专业知识的过程。</li>
<li><strong>模型复杂度</strong>：对于非常复杂的数据模式，机器学习模型可能难以捕捉到这些模式。</li>
<li><strong>泛化能力</strong>：在面对未见过的数据时，一些机器学习模型可能泛化能力不足。</li>
</ol>
<p><strong>深度学习的优点</strong></p>
<ol type="1">
<li><strong>自动特征提取</strong>：深度学习模型能够自动从原始数据中提取特征，减少了人工特征工程的需求。</li>
<li><strong>处理复杂数据</strong>：深度学习特别擅长处理高维和复杂的数据，如图像、视频和语音。</li>
<li><strong>强大的表示能力</strong>：深度学习模型具有强大的表示能力，能够学习数据的多层次抽象。</li>
<li><strong>端到端学习</strong>：深度学习可以实现端到端的学习，即直接从输入到输出的映射，无需手动设计中间步骤。</li>
</ol>
<p><strong>深度学习的缺点</strong></p>
<ol type="1">
<li><strong>数据需求</strong>：深度学习模型通常需要大量的标注数据来训练。</li>
<li><strong>计算资源</strong>：训练深度学习模型需要强大的计算资源，如GPU集群。</li>
<li><strong>可解释性</strong>：深度学习模型（尤其是大型神经网络）通常被认为是“黑箱”，难以解释其决策过程。</li>
<li><strong>过拟合风险</strong>：在有限的数据集上，深度学习模型可能会过拟合，导致在新数据上的性能不佳。</li>
</ol>
<p>总的来说，机器学习和深度学习各有优势和局限，它们在不同的应用场景下可以互补。随着技术的发展，两者之间的界限越来越模糊，例如，通过集成学习和迁移学习，可以将深度学习模型的泛化能力和机器学习模型的灵活性结合起来。</p>
<p>【例题3】谈谈机器学习在某领域（医疗、金融、电商、交通等）的应用</p>
<p>【解答3】（以下解答由AI生成）</p>
<p><strong>机器学习在医疗领域的应用</strong></p>
<p>机器学习在医疗领域的应用非常广泛，主要包括：</p>
<ol type="1">
<li><p><strong>疾病诊断与预测</strong>：通过分析患者的病史、基因组数据等信息，机器学习模型可以提前预测某些疾病的风险，帮助医生制定个性化的预防和治疗方案。例如，谷歌的深度学习模型通过分析视网膜扫描图像，能够准确预测糖尿病视网膜病变等眼疾，其诊断准确率媲美专业医生。</p></li>
<li><p><strong>医学影像识别</strong>：机器学习模型能够实现对X光片、CT扫描、MRI等影像的自动分析，提高影像学诊断的准确率，降低误诊率。</p></li>
<li><p><strong>药物研发与筛选</strong>：机器学习能够加速新药发现与优化，通过学习化学结构、生物活性、副作用等数据，预测化合物的药效，辅助药物设计与候选分子筛选，显著缩短研发周期。</p></li>
</ol>
<p><strong>机器学习在金融领域的应用</strong></p>
<p>机器学习在金融领域的应用包括：</p>
<ol type="1">
<li><p><strong>风险评估与信用评估</strong>：金融机构利用机器学习模型分析客户的历史贷款记录、还款习惯等数据，评估其信用风险并定制个性化的贷款方案。</p></li>
<li><p><strong>交易策略</strong>：机器学习模型在投资预测中的应用也越来越普遍，例如，量化分析师使用机器学习算法分析市场数据，识别规律，实现高频交易。</p></li>
<li><p><strong>欺诈检测</strong>：机器学习模型能够实时监测交易行为，识别异常模式，及时预警并拦截潜在欺诈交易。</p></li>
</ol>
<p><strong>机器学习在电商领域的应用</strong></p>
<p>机器学习在电商领域的应用主要体现在：</p>
<ol type="1">
<li><p><strong>推荐系统</strong>：电商平台利用机器学习技术，根据用户的购买历史、浏览行为等构建个性化推荐模型，提升商品转化率与用户满意度。</p></li>
<li><p><strong>库存优化与需求预测</strong>：零售商运用机器学习预测未来销售趋势，精准管理库存水平，避免过度库存导致的资金占用与滞销风险。</p></li>
</ol>
<p><strong>机器学习在交通领域的应用</strong></p>
<p>机器学习在交通领域的应用包括：</p>
<ol type="1">
<li><p><strong>交通流量预测与拥堵缓解</strong>：通过分析历史交通数据，机器学习模型可以预测未来的交通流量，帮助交通管理部门优化交通流量分配，减少交通拥堵和事故的发生。</p></li>
<li><p><strong>智能交通管理</strong>：机器学习技术可以用于实时监测和预测交通状况，优化交通流量分配，提高交通的效率和安全性。</p></li>
<li><p><strong>自动驾驶</strong>：自动驾驶汽车依托深度学习、强化学习等技术，实现环境感知、路径规划、决策控制等功能。</p></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E7%AC%94%E8%AE%B0/" class="category-chain-item">笔记</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>北航机器学习期末考试例题汇总</div>
      <div>https://suzumiyaakizuki.github.io/2024/12/21/机器学习期末考试例题汇总/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>SuzumiyaAkizuki</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年12月21日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
              <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">
              <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                <i class="iconfont icon-sa"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/12/17/%E4%BD%BF%E7%94%A8Matlab%E8%AE%AD%E7%BB%83%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%8C%E6%88%90%E8%A1%A8%E6%83%85%E5%8C%85%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/" title="使用Matlab训练卷积神经网络完成表情包分类任务">
                        <span class="hidden-mobile">使用Matlab训练卷积神经网络完成表情包分类任务</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://lib.baomitu.com/gitalk/1.7.2/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"48fb14f9689ae0d11307","clientSecret":"091ab25a88e87bfd9d9d40d97d1d0d932e694059","repo":"SuzumiyaAkizuki.github.io","owner":"SuzumiyaAkizuki","admin":["SuzumiyaAkizuki"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"},
          {
            id: '1cca094f463fa356c1fc989bfb6c6282'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       Powered by: <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <br> Copyright © 2019 - 2024 凉宫秋月. All Rights Reserved. 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
